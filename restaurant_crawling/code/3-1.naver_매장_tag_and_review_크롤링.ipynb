{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 매장 -> 매장에 있는 tag "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제\n",
    " \n",
    "1. 추천순으로 긁어올지, 최신순으로 긁어올지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException\n",
    "from tqdm import tqdm\n",
    "import chromedriver_autoinstaller\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import requests\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거 함수\n",
    "# 정규 표현식으로 이모티콘, 특수문자, 아스키코드 제거\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^\\w\\s]|_'\n",
    "    result = re.sub(pattern, '', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>식당이름</th>\n",
       "      <th>업태구분</th>\n",
       "      <th>주소</th>\n",
       "      <th>메뉴</th>\n",
       "      <th>가격</th>\n",
       "      <th>방문자리뷰</th>\n",
       "      <th>블로그리뷰</th>\n",
       "      <th>검색어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>하영호신촌설렁탕 역삼로점</td>\n",
       "      <td>곰탕,설렁탕</td>\n",
       "      <td>서울 강남구 역삼로 215 1층</td>\n",
       "      <td>설렁탕</td>\n",
       "      <td>11,000원</td>\n",
       "      <td>397</td>\n",
       "      <td>13</td>\n",
       "      <td>역삼로 215, 신촌설렁탕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사보텐 압구정본점</td>\n",
       "      <td>돈가스</td>\n",
       "      <td>서울 강남구 압구정로32길 32 1층</td>\n",
       "      <td>시그니처카츠(히레)</td>\n",
       "      <td>18,500원</td>\n",
       "      <td>555</td>\n",
       "      <td>109</td>\n",
       "      <td>압구정로32길 32 캘리스코 사보텐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>피오렌티나</td>\n",
       "      <td>이탈리아음식</td>\n",
       "      <td>서울 강남구 논현로 841 제이비 미소 빌딩</td>\n",
       "      <td>디너 코스 1인</td>\n",
       "      <td>70,000원</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>논현로 841 피오렌티나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>압구정변강쇠떡볶이</td>\n",
       "      <td>떡볶이</td>\n",
       "      <td>서울 강남구 도산대로46길 21 한진로즈힐아파트 101동 상가117호</td>\n",
       "      <td>쌀떡볶이(4줄) 1인분</td>\n",
       "      <td>4,500원</td>\n",
       "      <td>1583</td>\n",
       "      <td>526</td>\n",
       "      <td>도산대로46길 21 압구정변강쇠떡볶이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>마포만두 역삼점</td>\n",
       "      <td>만두</td>\n",
       "      <td>서울 강남구 논현로 429</td>\n",
       "      <td>메뉴없음</td>\n",
       "      <td>가격없음</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>논현로 429 마포만두</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            식당이름    업태구분                                      주소  \\\n",
       "0  하영호신촌설렁탕 역삼로점  곰탕,설렁탕                       서울 강남구 역삼로 215 1층   \n",
       "1      사보텐 압구정본점     돈가스                    서울 강남구 압구정로32길 32 1층   \n",
       "2          피오렌티나  이탈리아음식                서울 강남구 논현로 841 제이비 미소 빌딩   \n",
       "3      압구정변강쇠떡볶이     떡볶이  서울 강남구 도산대로46길 21 한진로즈힐아파트 101동 상가117호   \n",
       "4       마포만두 역삼점      만두                          서울 강남구 논현로 429   \n",
       "\n",
       "             메뉴       가격  방문자리뷰  블로그리뷰                   검색어  \n",
       "0           설렁탕  11,000원    397     13        역삼로 215, 신촌설렁탕  \n",
       "1    시그니처카츠(히레)  18,500원    555    109   압구정로32길 32 캘리스코 사보텐  \n",
       "2      디너 코스 1인  70,000원     90     53         논현로 841 피오렌티나  \n",
       "3  쌀떡볶이(4줄) 1인분   4,500원   1583    526  도산대로46길 21 압구정변강쇠떡볶이  \n",
       "4          메뉴없음     가격없음     25      3          논현로 429 마포만두  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "original_res_df = pd.read_excel('./data/2-1_naver_매장_기본정보_크롤링.xlsx')\n",
    "original_res_df = original_res_df.drop(['담당'],axis=1)\n",
    "original_df = original_res_df.copy()\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 일반인 \n",
    "# import chromedriver_autoinstaller\n",
    "# chromedriver_autoinstaller.install()\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# 지선\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>식당이름</th>\n",
       "      <th>업태구분</th>\n",
       "      <th>주소</th>\n",
       "      <th>메뉴</th>\n",
       "      <th>가격</th>\n",
       "      <th>방문자리뷰</th>\n",
       "      <th>블로그리뷰</th>\n",
       "      <th>검색어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>볼피노</td>\n",
       "      <td>이탈리아음식</td>\n",
       "      <td>서울 강남구 도산대로45길 10-7 신사동 K빌딩</td>\n",
       "      <td>트러플 아란치니</td>\n",
       "      <td>19,000원</td>\n",
       "      <td>637</td>\n",
       "      <td>1370</td>\n",
       "      <td>도산대로45길 10-7, 볼피노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>뽕나무쟁이 선릉본점</td>\n",
       "      <td>족발,보쌈</td>\n",
       "      <td>서울 강남구 역삼로65길 31</td>\n",
       "      <td>모둠족발(중)</td>\n",
       "      <td>42,000원</td>\n",
       "      <td>2462</td>\n",
       "      <td>2229</td>\n",
       "      <td>역삼로65길 31 뽕족본점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>새마을식당 역삼스타타워점 직화</td>\n",
       "      <td>돼지고기구이</td>\n",
       "      <td>서울 강남구 테헤란로20길 19 엘지역삼에클라트 1층 새마을식당 직화구이전문점</td>\n",
       "      <td>열탄불고기(150g)</td>\n",
       "      <td>10,900원</td>\n",
       "      <td>439</td>\n",
       "      <td>89</td>\n",
       "      <td>테헤란로20길 19 새마을식당</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               식당이름    업태구분                                           주소  \\\n",
       "0               볼피노  이탈리아음식                  서울 강남구 도산대로45길 10-7 신사동 K빌딩   \n",
       "1        뽕나무쟁이 선릉본점   족발,보쌈                             서울 강남구 역삼로65길 31   \n",
       "2  새마을식당 역삼스타타워점 직화  돼지고기구이  서울 강남구 테헤란로20길 19 엘지역삼에클라트 1층 새마을식당 직화구이전문점   \n",
       "\n",
       "            메뉴       가격  방문자리뷰  블로그리뷰                검색어  \n",
       "0     트러플 아란치니  19,000원    637   1370  도산대로45길 10-7, 볼피노  \n",
       "1      모둠족발(중)  42,000원   2462   2229     역삼로65길 31 뽕족본점  \n",
       "2  열탄불고기(150g)  10,900원    439     89   테헤란로20길 19 새마을식당  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한번에 몇개씩 크롤링할지 정하는 코드 \n",
    "start_num = 3700 # 할 차례, 여기를 계속 수정해주세요. 하드코딩 ㅠㅋㅋㅋ 0부터 100개를 했으면 그 다음은 start_num = 100\n",
    "num = 300  # 몇개씩 크롤링할지(기본은 100개를 추천합니다. -> 30분)\n",
    "end_num = start_num + num\n",
    "res_df = original_df[start_num:end_num] # 맨 마지막 크롤링할떄는 end_num을 지우세요. [start_num:] <-이렇게 \n",
    "res_df = res_df.reset_index(drop=True)\n",
    "res_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "진행 중: 100%|██████████| 300/300 [1:21:25<00:00, 16.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# 빈 리스트 생성\n",
    "restaurant_name_list = []\n",
    "category_name_list = []\n",
    "price_list = []\n",
    "\n",
    "\n",
    "# 반복해서 태그를 수집하기 \n",
    "for i in tqdm(range(0, len(res_df)), desc='진행 중', position=0, leave=True):\n",
    "    name = res_df['검색어'][i]\n",
    "    driver.get('https://map.naver.com/p/search/{}'.format(name))\n",
    "    time.sleep(3)  \n",
    "\n",
    "    try :\n",
    "        if driver.find_elements(By.ID,'entryIframe') :\n",
    "            entryIframe = driver.find_element(By.ID,'entryIframe')\n",
    "            driver.switch_to.frame(entryIframe)\n",
    "    except :\n",
    "        pass \n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "    # 매장 정보에서 '리뷰'를 클릭하기 위해서 리뷰 href 속성을 가져온다. \n",
    "    try : \n",
    "        # '리뷰' 탭의 href 속성 가져오기\n",
    "        review_tab = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//a[contains(text(), \"리뷰\")]'))\n",
    "        )\n",
    "\n",
    "        # 리뷰 탭의 a 주소 가져오기\n",
    "        review_url = review_tab.get_attribute('href')\n",
    "        if review_url == 'https://m.place.naver.com/my/policy/visitorReview' :\n",
    "            continue\n",
    "        else : \n",
    "            driver.get(review_url)\n",
    "            time.sleep(2.2)  \n",
    "    except :\n",
    "        continue \n",
    "\n",
    "\n",
    "    # # 리뷰 탭으로 이동합니다.      \n",
    "    # driver.get(review_url)\n",
    "    # time.sleep(2.2)  \n",
    "\n",
    "    try :\n",
    "        # 리뷰 탭에서 '더보기' 버튼을 클릭합니다. \n",
    "        more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'a.dP0sq'))\n",
    "        )\n",
    "        more_button.click()\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "    # 끝까지 스크롤을 합니다. \n",
    "    for _ in range(4):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.5) \n",
    "\n",
    "    # HTML 추출\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    items = soup.select('ul.K4J9r li.MHaAm, ul.K4J9r li.MHaAm')\n",
    "\n",
    "\n",
    "    # 매장명/태그/인원수를 가져옵니다. \n",
    "    \n",
    "    for item in items:\n",
    "        restaurant_name_list.append(name)\n",
    "        try :\n",
    "            category_name_list.append(item.text.split('\"')[1])\n",
    "            price_list.append(int(''.join(filter(str.isdigit, item.text))))\n",
    "        except :\n",
    "            category_name_list.append( '리뷰 10개 미만')\n",
    "            price_list.append('')\n",
    "     \n",
    "    # 차곡차곡 저장합니다. \n",
    "    data_list = {\n",
    "        '매장명': restaurant_name_list,\n",
    "        'tag': category_name_list,\n",
    "        '인원': price_list }\n",
    "\n",
    "result_df = pd.DataFrame(data_list)\n",
    "\n",
    "# 엑셀로 저장합니다. \n",
    "result_df.to_excel(f'./data/restaurant_tag_data/restaurant_tag_df_{start_num}_{end_num}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 모든 데이터프레임을 하나로 합치기\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 결과를 새로운 xlsx 파일로 저장\u001b[39;00m\n\u001b[0;32m     27\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_restaurant_tags.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hare0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hare0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:294\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m     92\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\hare0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:351\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    348\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# 폴더 안에 있는 엑셀 파일 하나로 합치기 \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 폴더 경로 설정\n",
    "folder_path = './Data/restaurant_tag_data'\n",
    "\n",
    "# 폴더 내의 모든 xlsx 파일 목록 가져오기\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# 빈 데이터프레임 리스트 생성\n",
    "df_list = []\n",
    "\n",
    "# 모든 xlsx 파일 읽어서 데이터프레임 리스트에 추가\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df_list.append(df)\n",
    "\n",
    "# 모든 데이터프레임을 하나로 합치기\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 결과를 새로운 xlsx 파일로 저장\n",
    "output_file = 'combined_restaurant_tags.xlsx'\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f'All data has been combined and saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------아래는 리뷰---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음식점 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 빈 리스트 생성\n",
    "# user_id_list = []\n",
    "# content_list = []\n",
    "# date_list = []  \n",
    "# revisit_list = []\n",
    "# restaurant_name_list = []\n",
    "# sub_info_list = []\n",
    "# # visit_method_list = []\n",
    "# # wait_time_list = []\n",
    "# # purpose_list = []\n",
    "# # visit_with_list =[]\n",
    "\n",
    "# # 해민 \n",
    "# # webdriver_manager를 사용하여 ChromeDriver 다운로드 및 설정\n",
    "\n",
    "# chromedriver_autoinstaller.install()\n",
    "# driver = webdriver.Chrome()\n",
    "# # 지선\n",
    "# # driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# scroll_num = 5\n",
    "# total_iterations = len(res_df)\n",
    "# for i in tqdm(range(total_iterations),desc='진행 중',position=0, leave= True):\n",
    "  \n",
    "#     name = res_df['검색어'][i]\n",
    "#     driver.get('https://map.naver.com/p/search/{}'.format(name))\n",
    "\n",
    "#     time.sleep(3)  \n",
    "#     try :\n",
    "#         if driver.find_elements(By.ID,'entryIframe') :\n",
    "#             entryIframe = driver.find_element(By.ID,'entryIframe')\n",
    "#             driver.switch_to.frame(entryIframe)\n",
    "#     except :\n",
    "#         pass \n",
    "\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     try : \n",
    "#         # '리뷰' 탭의 href 속성 가져오기\n",
    "#         review_tab_href = soup.find('a', {'class': 'tpj9w _tab-menu', 'aria-selected': 'true'}).get('href')\n",
    "#         review_url = 'https://pcmap.place.naver.com'+review_tab_href\n",
    "\n",
    "#         driver.get(review_url)\n",
    "#         time.sleep(2.2)  \n",
    "\n",
    "#     except :\n",
    "#         print('끝')\n",
    "\n",
    "#     # 현재 페이지 URL 가져오기\n",
    "#     current_url = driver.current_url\n",
    "\n",
    "#     try : \n",
    "#         # 리뷰 url로 이동 \n",
    "#         modified_url = current_url.replace('/home', '/review/visitor')\n",
    "#         driver.get(modified_url)\n",
    "#     except :\n",
    "#         continue\n",
    "#         # 리뷰 스크래핑 시작\n",
    "#     time.sleep(3)\n",
    "#     try:\n",
    "#         # ------------ 리뷰, 태그 '내용 더보기' 버튼 클릭 ----------------------\n",
    "#         review_buttons = driver.find_elements(By.CLASS_NAME,'xHaT3')  \n",
    "#         for button1 in review_buttons:\n",
    "#             try:\n",
    "#                 button1.click()\n",
    "#             except :\n",
    "#                 pass\n",
    "                \n",
    "            \n",
    "#             tag_buttons = driver.find_elements(By.CSS_SELECTOR,'.sIv5s.WPk67')  \n",
    "#             for button2 in tag_buttons:\n",
    "#                 try:\n",
    "#                     button2.click()\n",
    "#                 except :\n",
    "#                     pass\n",
    "#          # 리뷰 크롤링 시작\n",
    "#         html = driver.page_source\n",
    "#         soup = BeautifulSoup(html, 'lxml')\n",
    "#         reviews = soup.select('li.owAeM') \n",
    "#         for r in reviews:\n",
    "#             user_id = r.select_one('div.qgLL3 span.P9EZi')\n",
    "#             content = r.select_one('div.vg7Fp span.zPfVt')\n",
    "#             sub_info = r.select_one('div.MnhVd a.SbJ__').text if r.select_one('div.MnhVd a.SbJ__') else ' '\n",
    "#             date = r.select_one('div.jxc2b div.D40bm span.CKUdu time')\n",
    "#             revisit = r.select_one('div.jxc2b div.D40bm span.CKUdu:nth-of-type(2)')\n",
    "            \n",
    "#             # 없는 경우 \n",
    "#             user_id_text = user_id.text if user_id else ''\n",
    "#             content_text = content.text if content else ''          \n",
    "#             date_text = date.text if date else ''\n",
    "#             revisit_text = revisit.text.replace('번째 방문', '') if revisit else ''\n",
    "            \n",
    "#             # 리스트에 합치기\n",
    "#             restaurant_name_list.append(name)\n",
    "#             user_id_list.append(user_id_text)\n",
    "#             sub_info_list.append(sub_info)\n",
    "\n",
    "#             date_list.append(date_text)\n",
    "#             revisit_list.append(revisit_text)\n",
    "#             content_list.append(remove_special_characters(content_text))\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "# # 데이터프레임 얹히기\n",
    "# review_data_list = {\n",
    "#     '검색어': restaurant_name_list,\n",
    "#     'user_id': user_id_list,\n",
    "#     'review': content_list,\n",
    "#     'date': date_list,\n",
    "#     'revisit': revisit_list,\n",
    "#     'sub_info' : sub_info_list\n",
    "# }\n",
    "# driver.quit()\n",
    "# # 리뷰 데이터 프레임 완성\n",
    "# review_result_df = pd.DataFrame(review_data_list)\n",
    "\n",
    "# review_result_df\n",
    "\n",
    "\n",
    "\n",
    "# ## 결과 데이터에 검색어 칼럼 추가\n",
    "# ## 추후에 인덱스로 쓸 예정이기 떄문\n",
    "\n",
    "# review_result_df.to_excel(f'./data/restaurant_review_data/restaurant_review_df_{start_num}_{end_num}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # #스크롤\n",
    "        # for _ in range(scroll_num):\n",
    "        #     current_scroll_position = driver.execute_script('return window.scrollY;') # 초기 스크롤 위치 \n",
    "\n",
    "        #     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        #     time.sleep(2) \n",
    "            \n",
    "        #     # # 'TeItc' 클래스를 가진 요소가 클릭 가능할 때까지 기다리고, 보이도록 스크롤\n",
    "        #     # button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'TeItc')))\n",
    "        #     # driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "        #     # button.click()\n",
    "        #     # # 더보기 클릭\n",
    "        #     # button = driver.find_element(By.CLASS_NAME,'fvwqf')\n",
    "        #     # button.click()\n",
    "        #     # # 'fvwqf' 클래스를 가진 요소가 나타날 때까지 스크롤\n",
    "        #     # driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "        #     # button.click()\n",
    "\n",
    "        #     # ------------ 리뷰, 태그 '내용 더보기' 버튼 클릭 ----------------------\n",
    "        #     review_buttons = driver.find_elements(By.CLASS_NAME,'xHaT3')  \n",
    "        #     for button1 in review_buttons:\n",
    "        #         try:\n",
    "        #             button1.click()\n",
    "        #         except :\n",
    "        #             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 리뷰는 최대 11개\n",
    "# # url도 가져오겠습니다.\n",
    "\n",
    "\n",
    "# # 빈 리스트 생성\n",
    "# user_id_list = []\n",
    "# content_list = []\n",
    "# date_list = []  \n",
    "# revisit_list = []\n",
    "# tag_category_name_list = []\n",
    "# restaurant_name_list = []\n",
    "# review_category_name_list = []\n",
    "\n",
    "# # 해민 \n",
    "# # webdriver_manager를 사용하여 ChromeDriver 다운로드 및 설정\n",
    "\n",
    "# chromedriver_autoinstaller.install()\n",
    "# driver = webdriver.Chrome()\n",
    "# # 지선\n",
    "# # driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# scroll_num = 5\n",
    "\n",
    "# for i in range(0,len(new_res_df_test)):\n",
    "  \n",
    "#     name = new_res_df_test['검색어'][i]\n",
    "#     driver.get('https://map.naver.com/p/search/{}'.format(name))\n",
    "\n",
    "#     time.sleep(3)  \n",
    "#     try :\n",
    "#         if driver.find_elements(By.ID,'entryIframe') :\n",
    "#             entryIframe = driver.find_element(By.ID,'entryIframe')\n",
    "#             driver.switch_to.frame(entryIframe)\n",
    "#     except :\n",
    "#         pass \n",
    "\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     try : \n",
    "#         # '리뷰' 탭의 href 속성 가져오기\n",
    "#         review_tab_href = soup.find('a', {'class': 'tpj9w _tab-menu', 'aria-selected': 'true'}).get('href')\n",
    "#         review_url = 'https://pcmap.place.naver.com'+review_tab_href\n",
    "\n",
    "#         driver.get(review_url)\n",
    "#         time.sleep(2.2)  \n",
    "\n",
    "#     except :\n",
    "#         print('끝')\n",
    "\n",
    "#     # 현재 페이지 URL 가져오기\n",
    "#     current_url = driver.current_url\n",
    "\n",
    "#     try : \n",
    "#         # 리뷰 url로 이동 \n",
    "#         modified_url = current_url.replace('/home', '/review/visitor')\n",
    "#         driver.get(modified_url)\n",
    "#     except :\n",
    "#         continue\n",
    "\n",
    "#     # 리뷰 스크래핑 시작\n",
    "#     try:\n",
    "#         # 스크롤\n",
    "#         for _ in range(scroll_num):\n",
    "#             current_scroll_position = driver.execute_script('return window.scrollY;') # 초기 스크롤 위치 \n",
    "\n",
    "#             driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#             time.sleep(2) \n",
    "            \n",
    "#             # 'TeItc' 클래스를 가진 요소가 클릭 가능할 때까지 기다리고, 보이도록 스크롤\n",
    "#             button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'TeItc')))\n",
    "#             driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "#             button.click()\n",
    "\n",
    "#             # # 더보기 클릭\n",
    "#             # button = driver.find_element(By.CLASS_NAME,'fvwqf')\n",
    "#             # button.click()\n",
    "\n",
    "#             # # 'fvwqf' 클래스를 가진 요소가 나타날 때까지 스크롤\n",
    "#             # driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "#             # button.click()\n",
    "\n",
    "#             # ------------ 리뷰, 태그 '내용 더보기' 버튼 클릭 ----------------------\n",
    "#             # review_buttons = driver.find_elements(By.CLASS_NAME,'xHaT3')  \n",
    "#             # for button1 in review_buttons:\n",
    "#             #     try:\n",
    "#             #         button1.click()\n",
    "#             #     except :\n",
    "#             #         pass\n",
    "\n",
    "#             tag_buttons = driver.find_elements(By.CLASS_NAME,'.gyAGI a.P1zUJ.ZGKcF')  \n",
    "#             for button2 in tag_buttons:\n",
    "#                 try:\n",
    "#                     button2.click()\n",
    "#                 except :\n",
    "#                     pass\n",
    "#             # ----------------------------------------------\n",
    "#             time.sleep(3)\n",
    "\n",
    "#             # ---------------스크롤위치가 변하지 않으면 리뷰를 다 크롤링한 것이니까 탈출 -------------------------\n",
    "#             # 현재 스크롤 \n",
    "#             new_scroll_position = driver.execute_script('return window.scrollY;')\n",
    "\n",
    "#             # 현재 위치와 이전 위치가 같으면 반복문 탈출\n",
    "#             if new_scroll_position == current_scroll_position:\n",
    "#                 break\n",
    "\n",
    "#             # 이전 스크롤 위치 업데이트\n",
    "#             prev_scroll_position = current_scroll_position\n",
    "#             # -------------------------------------------------------------------------------------------------\n",
    "            \n",
    "#             html = driver.page_source\n",
    "#             soup = BeautifulSoup(html, 'lxml')\n",
    "#             reviews = soup.select('li.owAeM') \n",
    "\n",
    "#         # 리뷰 크롤링 시작\n",
    "#         for r in reviews:\n",
    "#             user_id = r.select_one('div.qgLL3 span.P9EZi')\n",
    "#             review_count = r.select_one('div.Gt2_9 span.RNn6x:nth-of-type(1)')\n",
    "#             photo_count = r.select_one('div.Gt2_9 span.RNn6x:nth-of-type(2)')\n",
    "            \n",
    "#             content = r.select_one('div.vg7Fp span.zPfVt')\n",
    "            \n",
    "#             try:\n",
    "#                 tag = r.select_one('div.ERkm0 span.sIv5s')\n",
    "#             except:\n",
    "#                 tag = \"\"\n",
    "            \n",
    "#             date = r.select_one('div.jxc2b div.D40bm span.CKUdu time')\n",
    "#             revisit = r.select_one('div.jxc2b div.D40bm span.CKUdu:nth-of-type(2)')\n",
    "            \n",
    "#             # 없는 경우 \n",
    "#             user_id_text = user_id.text if user_id else ''\n",
    "#             review_count_text = review_count.text if review_count else ''\n",
    "#             photo_count_text = photo_count.text if photo_count else ''\n",
    "#             content_text = content.text if content else ''\n",
    "#             tag_text = tag.text if tag else ''\n",
    "#             date_text = date.text if date else ''\n",
    "#             revisit_text = revisit.text.replace('번째 방문', '') if revisit else ''\n",
    "            \n",
    "#             # 리스트에 합치기\n",
    "#             restaurant_name_list.append(name)\n",
    "#             user_id_list.append(user_id_text)\n",
    "#             review_category_name_list.append(tag_text)\n",
    "#             date_list.append(date_text)\n",
    "#             revisit_list.append(revisit_text)\n",
    "#             content_list.append(remove_special_characters(content_text))\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "\n",
    "# # 데이터프레임 얹히기\n",
    "# review_data_list = {\n",
    "#     '검색어': restaurant_name_list,\n",
    "#     'user_id': user_id_list,\n",
    "#     'review': content_list,\n",
    "#     'date': date_list,\n",
    "#     'revisit': revisit_list,\n",
    "#     'tag': review_category_name_list\n",
    "# }\n",
    "\n",
    "# # 리뷰 데이터 프레임 완성\n",
    "# review_result_df = pd.DataFrame(review_data_list)\n",
    "\n",
    "# review_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_result_df.to_excel(f'./data/restaurant_review_data/restaurant_review_df_{start_num}_{end_num}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
